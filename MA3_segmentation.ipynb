{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 3: Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third notebook deals with the separation of the data set into person and company data entries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "\n",
    "1. **re**  - This is a library to process regular expressions. \n",
    "\n",
    "2. **Numpy** - Numpy is a library for the easy use of vectors, matrices or arrays in general. It simplifies various numerical operations. \n",
    "\n",
    "3. **Codecs** - This module provides access to the most common Python encoders and decoders for example to be used for text encoding.\n",
    "\n",
    "4. **Pandas** - Pandas is a library to analyze and to manage data. It is used to create tables.\n",
    "\n",
    "5. **NLTK** - This is a popular library to work with human language data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29650,
     "status": "ok",
     "timestamp": 1636615404299,
     "user": {
      "displayName": "Dewi K",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03606647171577901504"
     },
     "user_tz": -60
    },
    "id": "bTxva72XhIlJ",
    "outputId": "da823c15-2cf7-4408-9361-dcf1f5c92676",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "import re\n",
    "import numpy\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "# #-*- coding: utf-8 -*-\n",
    "# from google.colab import drive \n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the current address book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpPznc_zhIlL"
   },
   "outputs": [],
   "source": [
    "filedir='./Outputs/2_Full_address_book.txt'\n",
    "address_book_txt=codecs.open(filedir, \"r\", \"utf-8\")\n",
    "address_book=address_book_txt.read()\n",
    "address_book_txt.close()\n",
    "\n",
    "address_book = re.sub(r'\\s*(\\n)', r'\\1', address_book)\n",
    "address_book = re.sub(r'([a-zäöüß]+)([A-Z]{1})(\\.)', r'\\1, \\2\\3', address_book)\n",
    "address_book_list = address_book.split('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation into person or company entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jef5ms6rhIlM"
   },
   "outputs": [],
   "source": [
    "'''Delete entries with less than 3 comma'''\n",
    "current = 0\n",
    "temp = []\n",
    "temps = []\n",
    "for info in address_book_list:\n",
    "    #if entry only contains 2 elements, delete entry\n",
    "    if len(info.split(' ')) < 4:\n",
    "        continue\n",
    "    else:\n",
    "        info = info\n",
    "    temp.append(info)\n",
    "address_book_list = temp\n",
    "\n",
    "address_book = '\\r\\n'.join(address_book_list)\n",
    "address_book_list1 = address_book.split('\\r\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gczJVvHhIlO"
   },
   "outputs": [],
   "source": [
    "'''separating person entries and company entries'''\n",
    "#identifying person entries by their syntax\n",
    "#all entries not fitting the syntax get safed as other\n",
    "\n",
    "person_entries = []\n",
    "person_entries1 = []\n",
    "other_entries = []\n",
    "company_entries = [] #entries in \"other list\" with company keywords AND company_p_entries\n",
    "company_p_entries = [] #entries that have person entry syntax, but contain company keywords\n",
    "trash_entries = []\n",
    "trash_entries_akey = []\n",
    "owner_entries = []\n",
    "\n",
    "\n",
    "for i in range(0, len(address_book_list)):\n",
    "    #match = re.search(r'((([A-ZÄÖÜa-zäöüß\\-\\s]*)(\\,\\s)([0-9]+\\,\\s))?(\\**\\s*)([A-ZÄÖÜa-zäöüß]{3,}[\\.\\,]+\\s?)([A-ZÄÖÜ]?[a-zäöü]{0,2}[\\.\\,]{1,2}\\s*)((([A-ZÄÖÜa-zäöüß]+[\\-\\.\\,\\s\\(u]+)*\\s*[A-ZÄÖÜ\\sa-zäöüß]*\\(*[A-ZÄÖÜ\\sa-zäöü]*\\)*[\\.\\,]*\\s*)([HIV0Ol1]*)*(\\w+\\.*\\s[1-9]+[a-z]?)*))', address_book_list[i])\n",
    "    match = re.search(r'((([A-ZÄÖÜa-zäöüß\\-\\s]*)(\\,\\s)([0-9]+\\,\\s))?(\\*\\s)?([A-zÄÖÜ][a-zäöüß]{2,}\\s*([a-zäöüß])*[\\.\\,]*\\s*)(([A-ZÄÖÜ]{0,2}[a-zäöüß]{0,2}[\\.\\,]{1,2}\\s){1,2})(([A-ZÄÖÜfp][a-zäöüß\\-\\s]+)\\.*(\\-[A-ZÄÖÜ][a-zäöüß]*)*\\s*([A-ZÄÖÜ]?[a-zäöüß]*\\.?\\,?\\s?)(([A-ZÄÖÜ][a-zäöüß]*[\\s\\-]?)*\\.?\\s[0-9]{1,3})?(\\([a-zäöüß]+\\.?\\s([A-ZÄÖÜ]?[a-zäöüß]*\\-?\\s?)*\\)){0,1}(\\s*[HIV!l0O]+)*))', address_book_list[i])\n",
    "    if match:\n",
    "        person_entries.append(address_book_list[i])\n",
    "    else:\n",
    "        other_entries.append(address_book_list[i])\n",
    "\n",
    "#checking if entries in person_entries contain company keywords\n",
    "for j in range(0, len(person_entries)):\n",
    "    match = re.search(r'(\\(?G\\.\\-L\\.\\)?|\\(GL\\)|\\(L\\.?\\)|\\(?A\\.\\-G\\.?\\)?|Akt\\.\\-Ges\\.|Akt[i[eo]n|\\.]{0,1}\\-Ges[(ellschaft)|\\.]{0,1}|h[an]{0,2}dlg\\b|handlung\\b|Tuche|Ge[sf]{1}amtgeschlecht|[Bb]{1}rauerei\\b|[Bb]{1}rauh(aus)?\\b|[Ff]{1}abrik\\b|[Ff]{1}irma\\b|\\(C\\.\\)|Laden\\b|\\(L(a){0,1}d\\.\\)|Kaufl\\b|wäscherei[\\s-]{1}|GmbH|[Aa]{1}poth[ec]{1}ke\\b|[\\s-]{1}G\\.\\s{0,1}m\\.\\s{0,1}b\\.\\s{0,1}H[\\.]\\s{0,1}|[\\s-]{1}Fabrik\\b|fabrik\\b|[\\-]{0,1}firma\\b|Firma[\\-]{0,1}\\b|[Bb]{1}rauerei[\\,]{0,1}\\b|[Gg]{1}esell[-]{0,1}sch[aä]{1}ft|Gesch\\.|\\bGes\\.\\b|Drogerie\\b|[Ff]{1}iliale\\b|[Gg]{1}esch[aä]{1}ft\\b|lager\\b|[ -][Aa]{1}nstalt\\b|[Bb]{1}ank\\b|\\(C\\.?\\)|[ -]{1}[Gg]{1}enossenschaft|[Aa]telier\\b|zollamt\\b|[Aa]gentur\\b)', person_entries[j])\n",
    "    match_other = re.search(r'(Distrikt|Distr\\.|\\b[Vv]{1}om\\b|Zw\\.|\\bZw\\b|\\bzw\\b|Bei\\b|Zufuhrstra[ßh]e\\.|Einm[ü|i|.]+(nd)*(ung)*|\\(.+\\bzur\\b.*\\)|Go[fs]tenhof\\.|Lichtenhof\\.|Wäschershof\\.)', person_entries[j])\n",
    "    match_owner = re.search(r'(gemeinde\\b|zollamt\\b|Staats[äaü]rar|Eisenbahnärar|Militärärar)', person_entries[j])\n",
    "    if match:\n",
    "        #print('Der Treffer: ' + str(person_entries[j]))\n",
    "        company_p_entries.append(person_entries[j])\n",
    "        company_entries.append(person_entries[j])\n",
    "    else:\n",
    "        if match_other:\n",
    "            trash_entries.append(person_entries[j])\n",
    "        elif match_owner:\n",
    "            owner_entries.append(person_entries[j])\n",
    "        else:\n",
    "            person_entries1.append(person_entries[j])\n",
    "\n",
    "#storing person entries in person_txt\n",
    "persons = '\\r\\n'.join(person_entries)\n",
    "persons1 = '\\r\\n'.join(person_entries1)\n",
    "person_txt = open('./Outputs/2_persons.txt', 'w')\n",
    "person_txt.write(persons)\n",
    "person_txt.close()\n",
    "person1_txt = open('./Outputs/2_persons1.txt', 'w')\n",
    "person1_txt.write(persons1)\n",
    "person1_txt.close()\n",
    "\n",
    "other = '\\r\\n'.join(other_entries)\n",
    "\n",
    "#check the left entries, that are not identifyed as person entries, for keywords to identify companies\n",
    "#company_entries = []\n",
    "#trash_entries = []\n",
    "#trash_entries_akey = []\n",
    "\n",
    "for j in range(0, len(other_entries)):\n",
    "    match_company = re.search(r'([A-ZÄÖÜa-zäöüß\\-\\s]*)(\\,\\s)([0-9]+\\,\\s)?(\\*\\s)\\s*[a-zäöüßA-ZÄÖÜ\\,\\.\\-\\s\\°]*(\\(?G\\.\\-L\\.\\)?|\\(GL\\)|\\(L\\.?\\)|\\(?A\\.\\-G\\.?\\)?|Akt\\.\\-Ges\\.|Akt[i[eo]n|\\.]{0,1}\\-Ges[(ellschaft)|\\.]{0,1}|h[an]{0,2}dlg\\b|handlung\\b|Tuche|Ge[sf]{1}amtgeschlecht|[Bb]{1}rauerei\\b|[Bb]{1}rauh(aus)?\\b|[Ff]{1}abrik\\b|[Ff]{1}irma\\b|\\(C\\.\\)|Laden\\b|\\(L(a){0,1}d\\.\\)|Kaufl\\b|wäscherei[\\s-]{1}|GmbH|[Aa]{1}poth[ec]{1}ke\\b|[\\s-]{1}G\\.\\s{0,1}m\\.\\s{0,1}b\\.\\s{0,1}H[\\.]\\s{0,1}|[\\s-]{1}Fabrik\\b|fabrik[\\,]{0,1}\\b|[\\-]{0,1}firma\\b|Firma[\\-]{0,1}\\b|[Bb]{1}rauerei[\\,]{0,1}\\b|[Gg]{1}esell[-]{0,1}sch[aä]{1}ft|Gesch\\.|\\bGes\\.\\b|Drogerie\\b|[Ff]{1}iliale\\b|[Gg]{1}esch[aä]{1}ft\\b|lager\\b|[ -][Aa]{1}nstalt\\b|[Bb]{1}ank\\b|\\(C\\.?\\)|[ -]{1}[Gg]{1}enossenschaft|[Aa]telier\\b|zollamt\\b|[Aa]gentur\\b)[a-zäöüßA-ZÄÖÜ\\,\\.\\-\\t\\:\\)0-9]*', other_entries[j])\n",
    "    match_owner = re.search(r'(gemeinde\\b|zollamt\\b|Staats[äaü]rar|Eisenbahnärar|Militärärar)', other_entries[j])\n",
    "    if match_company:\n",
    "        company_entries.append(other_entries[j])\n",
    "    elif match_owner:\n",
    "        owner_entries.append(other_entries[j])\n",
    "    else:\n",
    "        trash_entries_akey.append(other_entries[j])\n",
    "\n",
    "#storing company entries in company_txt\n",
    "companies_p = '\\r\\n'.join(company_p_entries)\n",
    "company_p_txt =open('./Outputs/2_companies_p.txt', 'w')\n",
    "company_p_txt.write(companies_p)\n",
    "company_p_txt.close()\n",
    "\n",
    "companies = '\\r\\n'.join(company_entries)\n",
    "company_txt =open('./Outputs/2_companies.txt', 'w')\n",
    "company_txt.write(companies)\n",
    "company_txt.close()\n",
    "\n",
    "#storing trash for review\n",
    "trash = '\\r\\n'.join(trash_entries)\n",
    "trash_txt =open('./Outputs/2_trash.txt', 'w')\n",
    "trash_txt.write(trash)\n",
    "trash_txt.close()\n",
    "\n",
    "trash_akey = '\\r\\n'.join(trash_entries_akey)\n",
    "trash_txt =open('./Outputs/2_trash_akey.txt', 'w')\n",
    "trash_txt.write(trash_akey)\n",
    "trash_txt.close()\n",
    "\n",
    "ownedByCity = '\\r\\n'.join(owner_entries)\n",
    "ownedByCity_txt =open('./Outputs/2_ownedByCity.txt', 'w')\n",
    "ownedByCity_txt.write(ownedByCity)\n",
    "ownedByCity_txt.close()\n",
    "\n",
    "#person_entries1\n",
    "#company_entries\n",
    "#other_entries\n",
    "#trash_entries_akey"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
