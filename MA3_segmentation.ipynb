{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 3: Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third notebook deals with the separation of the data set into person and company data entries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "\n",
    "1. **re**  - This is a library to process regular expressions. \n",
    "\n",
    "2. **Numpy** - Numpy is a library for the easy use of vectors, matrices or arrays in general. It simplifies various numerical operations. \n",
    "\n",
    "3. **Codecs** - This module provides access to the most common Python encoders and decoders for example to be used for text encoding.\n",
    "\n",
    "4. **Pandas** - Pandas is a library to analyze and to manage data. It is used to create tables.\n",
    "\n",
    "5. **NLTK** - This is a popular library to work with human language data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29650,
     "status": "ok",
     "timestamp": 1636615404299,
     "user": {
      "displayName": "Dewi K",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03606647171577901504"
     },
     "user_tz": -60
    },
    "id": "bTxva72XhIlJ",
    "outputId": "da823c15-2cf7-4408-9361-dcf1f5c92676",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "import re\n",
    "import numpy\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "# #-*- coding: utf-8 -*-\n",
    "# from google.colab import drive \n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the current address book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpPznc_zhIlL"
   },
   "outputs": [],
   "source": [
    "#filedir='/Users/ilona-dewikusardi/Desktop/Datensets/F_23_92.jpg/2_Full_address_book.txt'\n",
    "filedir='./Outputs/2_Full_address_book.txt'\n",
    "address_book_txt=codecs.open(filedir, \"r\", \"utf-8\")\n",
    "address_book=address_book_txt.read()\n",
    "address_book_txt.close()\n",
    "\n",
    "address_book = re.sub(r'\\s*(\\n)', r'\\1', address_book)\n",
    "address_book = re.sub(r'([a-zäöüß]+)([A-Z]{1})(\\.)', r'\\1, \\2\\3', address_book)\n",
    "address_book_list = address_book.split('\\n')\n",
    "\n",
    "#address_book_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation into person or company entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jef5ms6rhIlM"
   },
   "outputs": [],
   "source": [
    "'''Delete entries with less than 3 comma'''\n",
    "current = 0\n",
    "temp = []\n",
    "temps = []\n",
    "for info in address_book_list:\n",
    "    #if entry only contains 2 elements, delete entry\n",
    "    if len(info.split(' ')) < 4:\n",
    "        continue\n",
    "    else:\n",
    "        info = info\n",
    "    temp.append(info)\n",
    "address_book_list = temp\n",
    "\n",
    "#checking if length of entry (without the address) is > 10\n",
    "#for info1 in address_book_list:\n",
    "#    iSplit = info1.split(', ')\n",
    "#    rest = ', '.join(iSplit[2:])\n",
    "#    if len(rest) < 10:\n",
    "#        continue\n",
    "#    else:\n",
    "#        iSplit1 =', '.join(iSplit)\n",
    "#        temps.append(iSplit1)\n",
    "\n",
    "address_book = '\\r\\n'.join(address_book_list)\n",
    "address_book_list1 = address_book.split('\\r\\n')\n",
    "#address_book_list1\n",
    "#address_book\n",
    "#temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gczJVvHhIlO"
   },
   "outputs": [],
   "source": [
    "'''separating person entries and company entries'''\n",
    "#identifying person entries by their syntax\n",
    "#all entries not fitting the syntax get safed as other\n",
    "#address_book_list = address_book.split('\\r\\n')\n",
    "#address_book_list = address_book_list1\n",
    "#address_book_list = address_book_list2\n",
    "\n",
    "person_entries = []\n",
    "person_entries1 = []\n",
    "other_entries = []\n",
    "company_entries = [] #entries in \"other list\" with company keywords AND company_p_entries\n",
    "company_p_entries = [] #entries that have person entry syntax, but contain company keywords\n",
    "trash_entries = []\n",
    "trash_entries_akey = []\n",
    "owner_entries = []\n",
    "\n",
    "\n",
    "for i in range(0, len(address_book_list)):\n",
    "    #match = re.search(r'((([A-ZÄÖÜa-zäöüß\\-\\s]*)(\\,\\s)([0-9]+\\,\\s))?(\\**\\s*)([A-ZÄÖÜa-zäöüß]{3,}[\\.\\,]+\\s?)([A-ZÄÖÜ]?[a-zäöü]{0,2}[\\.\\,]{1,2}\\s*)((([A-ZÄÖÜa-zäöüß]+[\\-\\.\\,\\s\\(u]+)*\\s*[A-ZÄÖÜ\\sa-zäöüß]*\\(*[A-ZÄÖÜ\\sa-zäöü]*\\)*[\\.\\,]*\\s*)([HIV0Ol1]*)*(\\w+\\.*\\s[1-9]+[a-z]?)*))', address_book_list[i])\n",
    "    match = re.search(r'((([A-ZÄÖÜa-zäöüß\\-\\s]*)(\\,\\s)([0-9]+\\,\\s))?(\\*\\s)?([A-zÄÖÜ][a-zäöüß]{2,}\\s*([a-zäöüß])*[\\.\\,]*\\s*)(([A-ZÄÖÜ]{0,2}[a-zäöüß]{0,2}[\\.\\,]{1,2}\\s){1,2})(([A-ZÄÖÜfp][a-zäöüß\\-\\s]+)\\.*(\\-[A-ZÄÖÜ][a-zäöüß]*)*\\s*([A-ZÄÖÜ]?[a-zäöüß]*\\.?\\,?\\s?)(([A-ZÄÖÜ][a-zäöüß]*[\\s\\-]?)*\\.?\\s[0-9]{1,3})?(\\([a-zäöüß]+\\.?\\s([A-ZÄÖÜ]?[a-zäöüß]*\\-?\\s?)*\\)){0,1}(\\s*[HIV!l0O]+)*))', address_book_list[i])\n",
    "    if match:\n",
    "        person_entries.append(address_book_list[i])\n",
    "    else:\n",
    "        other_entries.append(address_book_list[i])\n",
    "\n",
    "#checking if entries in person_entries contain company keywords\n",
    "for j in range(0, len(person_entries)):\n",
    "    match = re.search(r'(\\(?G\\.\\-L\\.\\)?|\\(GL\\)|\\(L\\.?\\)|\\(?A\\.\\-G\\.?\\)?|Akt\\.\\-Ges\\.|Akt[i[eo]n|\\.]{0,1}\\-Ges[(ellschaft)|\\.]{0,1}|h[an]{0,2}dlg\\b|handlung\\b|Tuche|Ge[sf]{1}amtgeschlecht|[Bb]{1}rauerei\\b|[Bb]{1}rauh(aus)?\\b|[Ff]{1}abrik\\b|[Ff]{1}irma\\b|\\(C\\.\\)|Laden\\b|\\(L(a){0,1}d\\.\\)|Kaufl\\b|wäscherei[\\s-]{1}|GmbH|[Aa]{1}poth[ec]{1}ke\\b|[\\s-]{1}G\\.\\s{0,1}m\\.\\s{0,1}b\\.\\s{0,1}H[\\.]\\s{0,1}|[\\s-]{1}Fabrik\\b|fabrik\\b|[\\-]{0,1}firma\\b|Firma[\\-]{0,1}\\b|[Bb]{1}rauerei[\\,]{0,1}\\b|[Gg]{1}esell[-]{0,1}sch[aä]{1}ft|Gesch\\.|\\bGes\\.\\b|Drogerie\\b|[Ff]{1}iliale\\b|[Gg]{1}esch[aä]{1}ft\\b|lager\\b|[ -][Aa]{1}nstalt\\b|[Bb]{1}ank\\b|\\(C\\.?\\)|[ -]{1}[Gg]{1}enossenschaft|[Aa]telier\\b|zollamt\\b|[Aa]gentur\\b)', person_entries[j])\n",
    "    match_other = re.search(r'(Distrikt|Distr\\.|\\b[Vv]{1}om\\b|Zw\\.|\\bZw\\b|\\bzw\\b|Bei\\b|Zufuhrstra[ßh]e\\.|Einm[ü|i|.]+(nd)*(ung)*|\\(.+\\bzur\\b.*\\)|Go[fs]tenhof\\.|Lichtenhof\\.|Wäschershof\\.)', person_entries[j])\n",
    "    match_owner = re.search(r'(gemeinde\\b|zollamt\\b|Staats[äaü]rar|Eisenbahnärar|Militärärar)', person_entries[j])\n",
    "    if match:\n",
    "        #print('Der Treffer: ' + str(person_entries[j]))\n",
    "        company_p_entries.append(person_entries[j])\n",
    "        company_entries.append(person_entries[j])\n",
    "    else:\n",
    "        if match_other:\n",
    "            trash_entries.append(person_entries[j])\n",
    "        elif match_owner:\n",
    "            owner_entries.append(person_entries[j])\n",
    "        else:\n",
    "            person_entries1.append(person_entries[j])\n",
    "\n",
    "#storing person entries in person_txt\n",
    "persons = '\\r\\n'.join(person_entries)\n",
    "persons1 = '\\r\\n'.join(person_entries1)\n",
    "#person_txt = open(\"/Users/ilona-dewikusardi/Desktop/Datensets/F_23_92.jpg/2_persons.txt\", \"w\")\n",
    "person_txt = open('./Outputs/2_persons.txt', 'w')\n",
    "person_txt.write(persons)\n",
    "person_txt.close()\n",
    "person1_txt = open('./Outputs/2_persons1.txt', 'w')\n",
    "person1_txt.write(persons1)\n",
    "person1_txt.close()\n",
    "\n",
    "other = '\\r\\n'.join(other_entries)\n",
    "\n",
    "#check the left entries, that are not identifyed as person entries, for keywords to identify companies\n",
    "#company_entries = []\n",
    "#trash_entries = []\n",
    "#trash_entries_akey = []\n",
    "\n",
    "for j in range(0, len(other_entries)):\n",
    "    #match_company = re.search('\\s*[\\t]*[a-zäöüßA-ZÄÖÜ\\,\\.\\-\\t\\s\\°]*(\\(In|\\(Iu|\\(Jn|\\(Ju|[ ]*Inh\\.\\:|[ ]*Iuh\\.\\:|[ ]*Jnh\\.\\:|[ ]*Juh\\.\\:|[ ]*Inhab\\.\\:|[ ]*Inhaber\\.\\:|\\(Alleininhaber|[ -]{1}GmbH |[ -]{1}Vertr\\.|[ -]{1}Apotheke |hdlg.|[ -]{1}Apothcke |[ -]{1}G\\.[ ]{0,1}m\\.[ ]{0,1}b\\.[ ]{0,1}H[\\.][ ]{0,1}|[ -]{1}Fabrik |fabrik[\\,]{0,1} |[\\-]{0,1}firma |Firma[\\-]{0,1} |[Bb]{1}rauerei[\\,]{0,1} |[ -]{1}[Gg]{1}esell[-]{0,1}sch[aä]{1}ft |[ -]{1}Drogerie |[Fi]{1}iliale |{1}[Gg]{1}esch[aä]{1}ft | lager\\b |[ -][Aa]{1}nstalt |[Bb]{1}ank\\b |[ -]{1}[Gg]{1}enossenschaft)[a-zäöüßA-ZÄÖÜ\\,\\.\\-\\t\\: \\)0-9]*', other_entries[j])\n",
    "    match_company = re.search(r'([A-ZÄÖÜa-zäöüß\\-\\s]*)(\\,\\s)([0-9]+\\,\\s)?(\\*\\s)\\s*[a-zäöüßA-ZÄÖÜ\\,\\.\\-\\s\\°]*(\\(?G\\.\\-L\\.\\)?|\\(GL\\)|\\(L\\.?\\)|\\(?A\\.\\-G\\.?\\)?|Akt\\.\\-Ges\\.|Akt[i[eo]n|\\.]{0,1}\\-Ges[(ellschaft)|\\.]{0,1}|h[an]{0,2}dlg\\b|handlung\\b|Tuche|Ge[sf]{1}amtgeschlecht|[Bb]{1}rauerei\\b|[Bb]{1}rauh(aus)?\\b|[Ff]{1}abrik\\b|[Ff]{1}irma\\b|\\(C\\.\\)|Laden\\b|\\(L(a){0,1}d\\.\\)|Kaufl\\b|wäscherei[\\s-]{1}|GmbH|[Aa]{1}poth[ec]{1}ke\\b|[\\s-]{1}G\\.\\s{0,1}m\\.\\s{0,1}b\\.\\s{0,1}H[\\.]\\s{0,1}|[\\s-]{1}Fabrik\\b|fabrik[\\,]{0,1}\\b|[\\-]{0,1}firma\\b|Firma[\\-]{0,1}\\b|[Bb]{1}rauerei[\\,]{0,1}\\b|[Gg]{1}esell[-]{0,1}sch[aä]{1}ft|Gesch\\.|\\bGes\\.\\b|Drogerie\\b|[Ff]{1}iliale\\b|[Gg]{1}esch[aä]{1}ft\\b|lager\\b|[ -][Aa]{1}nstalt\\b|[Bb]{1}ank\\b|\\(C\\.?\\)|[ -]{1}[Gg]{1}enossenschaft|[Aa]telier\\b|zollamt\\b|[Aa]gentur\\b)[a-zäöüßA-ZÄÖÜ\\,\\.\\-\\t\\:\\)0-9]*', other_entries[j])\n",
    "    match_owner = re.search(r'(gemeinde\\b|zollamt\\b|Staats[äaü]rar|Eisenbahnärar|Militärärar)', other_entries[j])\n",
    "    if match_company:\n",
    "        company_entries.append(other_entries[j])\n",
    "    elif match_owner:\n",
    "        owner_entries.append(other_entries[j])\n",
    "    else:\n",
    "        trash_entries_akey.append(other_entries[j])\n",
    "\n",
    "#storing company entries in company_txt\n",
    "companies_p = '\\r\\n'.join(company_p_entries)\n",
    "#company_p_txt =open(\"/Users/ilona-dewikusardi/Desktop/Datensets/F_23_92.jpg/2_companies_p.txt\", \"w\")\n",
    "company_p_txt =open('./Outputs/2_companies_p.txt', 'w')\n",
    "company_p_txt.write(companies_p)\n",
    "company_p_txt.close()\n",
    "\n",
    "companies = '\\r\\n'.join(company_entries)\n",
    "#company_txt =open(\"/Users/ilona-dewikusardi/Desktop/Datensets/F_23_92.jpg/2_companies.txt\", \"w\")\n",
    "company_txt =open('./Outputs/2_companies.txt', 'w')\n",
    "company_txt.write(companies)\n",
    "company_txt.close()\n",
    "\n",
    "#storing trash for review\n",
    "trash = '\\r\\n'.join(trash_entries)\n",
    "#company_txt =open(\"/Users/ilona-dewikusardi/Desktop/Datensets/F_23_92.jpg/2_companies.txt\", \"w\")\n",
    "trash_txt =open('./Outputs/2_trash.txt', 'w')\n",
    "trash_txt.write(trash)\n",
    "trash_txt.close()\n",
    "\n",
    "trash_akey = '\\r\\n'.join(trash_entries_akey)\n",
    "#company_txt =open(\"/Users/ilona-dewikusardi/Desktop/Datensets/F_23_92.jpg/2_companies.txt\", \"w\")\n",
    "trash_txt =open('./Outputs/2_trash_akey.txt', 'w')\n",
    "trash_txt.write(trash_akey)\n",
    "trash_txt.close()\n",
    "\n",
    "ownedByCity = '\\r\\n'.join(owner_entries)\n",
    "#company_txt =open(\"/Users/ilona-dewikusardi/Desktop/Datensets/F_23_92.jpg/2_companies.txt\", \"w\")\n",
    "ownedByCity_txt =open('./Outputs/2_ownedByCity.txt', 'w')\n",
    "ownedByCity_txt.write(ownedByCity)\n",
    "ownedByCity_txt.close()\n",
    "\n",
    "#person_entries1\n",
    "#company_entries\n",
    "#other_entries\n",
    "#trash_entries_akey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1636615420700,
     "user": {
      "displayName": "Dewi K",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03606647171577901504"
     },
     "user_tz": -60
    },
    "id": "qenvFdVWrcVM",
    "outputId": "4be4a2a8-7321-47a6-f1e2-2a431b663b63"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'#Try first company, then person entries\\naddress_book_list2 = address_book.split(\\'\\r\\n\\')\\naddress_book_list2\\n#address_book_list = address_book_list2\\n\\ntest_person_entries = []\\ntest_person_entries1 = []\\ntest_other_entries = []\\ntest_company_entries = []\\ntest_trash_entries = []\\ntest_trash_as_entries = []\\n\\n\\n#checking the entries in person_entries again for \"(G.-L.)\" or \"(L.)\" which identify \"Geschäftslokal or Lokal\"\\nfor j in range(0, len(address_book_list2)):\\n    match = re.search(r\\'(\\\\(?G\\\\.\\\\-L\\\\.\\\\)?|\\\\(GL\\\\)|\\\\(L\\\\.?\\\\)|\\\\(?A\\\\.\\\\-G\\\\.?\\\\)?|Akt\\\\.\\\\-Ges\\\\.|Akt[i[eo]n|\\\\.]{0,1}\\\\-Ges[(ellschaft)|\\\\.]{0,1}|h[an]{0,2}dlg\\x08|Tuche|Ge[sf]{1}amtgeschlecht|[Bb]{1}rauerei\\x08|[Bb]{1}rauh(aus)?\\x08|[Ff]{1}abrik\\x08|[Ff]{1}irma\\x08|\\\\(C\\\\.\\\\)|Laden\\x08|\\\\(Ld\\\\.\\\\)|gemeinde\\x08|Kaufl\\x08|wäscherei[\\\\s-]{1}|GmbH|[\\\\s-]{1}Apoth[ec]{1}ke |Gebr\\x08|[\\\\s-]{1}G\\\\.\\\\s{0,1}m\\\\.\\\\s{0,1}b\\\\.\\\\s{0,1}H[\\\\.]\\\\s{0,1}|[\\\\s-]{1}Fabrik\\x08|fabrik[\\\\,]{0,1}\\x08|[\\\\-]{0,1}firma\\x08|Firma[\\\\-]{0,1}\\x08|[Bb]{1}rauerei[\\\\,]{0,1}\\x08|[Gg]{1}esell[-]{0,1}sch[aä]{1}ft|Gesch\\\\.|\\x08Ges\\\\.\\x08|Drogerie\\x08|[Ff]{1}iliale\\x08|[Gg]{1}esch[aä]{1}ft\\x08|lager\\x08|[ -][Aa]{1}nstalt\\x08|[Bb]{1}ank\\x08|\\\\(C\\\\.?\\\\)|[ -]{1}[Gg]{1}enossenschaft|[Aa]telier\\x08)\\', address_book_list2[j])\\n    match_other = re.search(r\\'(Distrikt|Distr\\\\.|\\x08[Vv]{1}om\\x08|\\x08Zw\\x08|\\x08zw\\x08|Bei\\x08)\\', address_book_list2[j])\\n    if match:\\n        #print(\\'Der Treffer: \\' + str(person_entries[j]))\\n        test_company_entries.append(address_book_list2[j])\\n    else:\\n        if match_other:\\n            test_trash_entries.append(address_book_list2[j])\\n        else:\\n            test_other_entries.append(address_book_list2[j])\\n\\nfor i in range(0, len(test_other_entries)):\\n    #match = re.search(r\\'((([A-ZÄÖÜa-zäöüß\\\\-\\\\s]*)(\\\\,\\\\s)([0-9]+\\\\,\\\\s))?(\\\\**\\\\s*)([A-ZÄÖÜa-zäöüß]{3,}[\\\\.\\\\,]+\\\\s?)([A-ZÄÖÜ]?[a-zäöü]{0,2}[\\\\.\\\\,]{1,2}\\\\s*)((([A-ZÄÖÜa-zäöüß]+[\\\\-\\\\.\\\\,\\\\s\\\\(u]+)*\\\\s*[A-ZÄÖÜ\\\\sa-zäöüß]*\\\\(*[A-ZÄÖÜ\\\\sa-zäöü]*\\\\)*[\\\\.\\\\,]*\\\\s*)([HIV0Ol1]*)*(\\\\w+\\\\.*\\\\s[1-9]+[a-z]?)*))\\', address_book_list[i])\\n    match_syntax = re.search(r\\'((([A-ZÄÖÜa-zäöüß\\\\-\\\\s]*)(\\\\,\\\\s)([0-9]+\\\\,\\\\s))?(\\\\*\\\\s)?([A-zÄÖÜ][a-zäöüß]{2,}\\\\s*([a-zäöüß])*[\\\\.\\\\,]*\\\\s*)(([A-ZÄÖÜ]{0,2}[a-zäöüß]{0,2}[\\\\.\\\\,]{1,2}\\\\s){1,2})(([A-ZÄÖÜfp][a-zäöüß\\\\-\\\\s]+)\\\\.*(\\\\-[A-ZÄÖÜ][a-zäöüß]*)*\\\\s*([A-ZÄÖÜ]?[a-zäöüß]*\\\\.?\\\\,?\\\\s?)(([A-ZÄÖÜ][a-zäöüß]*[\\\\s\\\\-]?)*\\\\.?\\\\s[0-9]{1,3})?(\\\\([a-zäöüß]+\\\\.?\\\\s([A-ZÄÖÜ]?[a-zäöüß]*\\\\-?\\\\s?)*\\\\)){0,1}(\\\\s*[HIV!l0O]+)*))\\', test_other_entries[i])\\n    if match_syntax:\\n        #print(\\'Person gefunden: \\' + str(match) + \\' Zeile: \\' + str(address_book_list[i]))\\n        test_person_entries.append(address_book_list[i])\\n    else:\\n        test_trash_as_entries.append(address_book_list[i])\\n\\npersons = \\'\\r\\n\\'.join(test_person_entries)\\ncompanies = \\'\\r\\n\\'.join(test_company_entries)\\nperson_txt = open(\\'/content/gdrive/MyDrive/MA Python/Outputs/2_test_persons.txt\\', \\'w\\')\\nperson_txt.write(persons)\\nperson_txt.close()\\ncompany_txt = open(\\'/content/gdrive/MyDrive/MA Python/Outputs/2_test_companies.txt\\', \\'w\\')\\ncompany_txt.write(companies)\\ncompany_txt.close()'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''#Try first company, then person entries\n",
    "address_book_list2 = address_book.split('\\r\\n')\n",
    "address_book_list2\n",
    "#address_book_list = address_book_list2\n",
    "\n",
    "test_person_entries = []\n",
    "test_person_entries1 = []\n",
    "test_other_entries = []\n",
    "test_company_entries = []\n",
    "test_trash_entries = []\n",
    "test_trash_as_entries = []\n",
    "\n",
    "\n",
    "#checking the entries in person_entries again for \"(G.-L.)\" or \"(L.)\" which identify \"Geschäftslokal or Lokal\"\n",
    "for j in range(0, len(address_book_list2)):\n",
    "    match = re.search(r'(\\(?G\\.\\-L\\.\\)?|\\(GL\\)|\\(L\\.?\\)|\\(?A\\.\\-G\\.?\\)?|Akt\\.\\-Ges\\.|Akt[i[eo]n|\\.]{0,1}\\-Ges[(ellschaft)|\\.]{0,1}|h[an]{0,2}dlg\\b|Tuche|Ge[sf]{1}amtgeschlecht|[Bb]{1}rauerei\\b|[Bb]{1}rauh(aus)?\\b|[Ff]{1}abrik\\b|[Ff]{1}irma\\b|\\(C\\.\\)|Laden\\b|\\(Ld\\.\\)|gemeinde\\b|Kaufl\\b|wäscherei[\\s-]{1}|GmbH|[\\s-]{1}Apoth[ec]{1}ke |Gebr\\b|[\\s-]{1}G\\.\\s{0,1}m\\.\\s{0,1}b\\.\\s{0,1}H[\\.]\\s{0,1}|[\\s-]{1}Fabrik\\b|fabrik[\\,]{0,1}\\b|[\\-]{0,1}firma\\b|Firma[\\-]{0,1}\\b|[Bb]{1}rauerei[\\,]{0,1}\\b|[Gg]{1}esell[-]{0,1}sch[aä]{1}ft|Gesch\\.|\\bGes\\.\\b|Drogerie\\b|[Ff]{1}iliale\\b|[Gg]{1}esch[aä]{1}ft\\b|lager\\b|[ -][Aa]{1}nstalt\\b|[Bb]{1}ank\\b|\\(C\\.?\\)|[ -]{1}[Gg]{1}enossenschaft|[Aa]telier\\b)', address_book_list2[j])\n",
    "    match_other = re.search(r'(Distrikt|Distr\\.|\\b[Vv]{1}om\\b|\\bZw\\b|\\bzw\\b|Bei\\b)', address_book_list2[j])\n",
    "    if match:\n",
    "        #print('Der Treffer: ' + str(person_entries[j]))\n",
    "        test_company_entries.append(address_book_list2[j])\n",
    "    else:\n",
    "        if match_other:\n",
    "            test_trash_entries.append(address_book_list2[j])\n",
    "        else:\n",
    "            test_other_entries.append(address_book_list2[j])\n",
    "\n",
    "for i in range(0, len(test_other_entries)):\n",
    "    #match = re.search(r'((([A-ZÄÖÜa-zäöüß\\-\\s]*)(\\,\\s)([0-9]+\\,\\s))?(\\**\\s*)([A-ZÄÖÜa-zäöüß]{3,}[\\.\\,]+\\s?)([A-ZÄÖÜ]?[a-zäöü]{0,2}[\\.\\,]{1,2}\\s*)((([A-ZÄÖÜa-zäöüß]+[\\-\\.\\,\\s\\(u]+)*\\s*[A-ZÄÖÜ\\sa-zäöüß]*\\(*[A-ZÄÖÜ\\sa-zäöü]*\\)*[\\.\\,]*\\s*)([HIV0Ol1]*)*(\\w+\\.*\\s[1-9]+[a-z]?)*))', address_book_list[i])\n",
    "    match_syntax = re.search(r'((([A-ZÄÖÜa-zäöüß\\-\\s]*)(\\,\\s)([0-9]+\\,\\s))?(\\*\\s)?([A-zÄÖÜ][a-zäöüß]{2,}\\s*([a-zäöüß])*[\\.\\,]*\\s*)(([A-ZÄÖÜ]{0,2}[a-zäöüß]{0,2}[\\.\\,]{1,2}\\s){1,2})(([A-ZÄÖÜfp][a-zäöüß\\-\\s]+)\\.*(\\-[A-ZÄÖÜ][a-zäöüß]*)*\\s*([A-ZÄÖÜ]?[a-zäöüß]*\\.?\\,?\\s?)(([A-ZÄÖÜ][a-zäöüß]*[\\s\\-]?)*\\.?\\s[0-9]{1,3})?(\\([a-zäöüß]+\\.?\\s([A-ZÄÖÜ]?[a-zäöüß]*\\-?\\s?)*\\)){0,1}(\\s*[HIV!l0O]+)*))', test_other_entries[i])\n",
    "    if match_syntax:\n",
    "        #print('Person gefunden: ' + str(match) + ' Zeile: ' + str(address_book_list[i]))\n",
    "        test_person_entries.append(address_book_list[i])\n",
    "    else:\n",
    "        test_trash_as_entries.append(address_book_list[i])\n",
    "\n",
    "persons = '\\r\\n'.join(test_person_entries)\n",
    "companies = '\\r\\n'.join(test_company_entries)\n",
    "person_txt = open('/content/gdrive/MyDrive/MA Python/Outputs/2_test_persons.txt', 'w')\n",
    "person_txt.write(persons)\n",
    "person_txt.close()\n",
    "company_txt = open('/content/gdrive/MyDrive/MA Python/Outputs/2_test_companies.txt', 'w')\n",
    "company_txt.write(companies)\n",
    "company_txt.close()'''\n",
    "#test_company_entries\n",
    "#test_person_entries\n",
    "#test_other_entries\n",
    "#test_trash_entries\n",
    "#test_trash_as_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOip3aT2hIlP"
   },
   "outputs": [],
   "source": [
    "'''Identifying person entries by their syntax'''\n",
    "#person_entries1 = []\n",
    "#other_entries1 = []\n",
    "\n",
    "Personen = re.findall(r'((([A-ZÄÖÜ][a-zäöüß\\-\\s]*)(\\,\\s)([0-9]+\\,\\s))?(\\**\\s*)(\\b[A-ZÄÖÜ][a-zäöüß]{3,}(\\s[a-zäöüß]*)?[\\.\\,]{1}\\s?)([A-ZÄÖÜ]{1,2}[a-zäöü]{0,2}[\\.\\,]{1,2}\\s*)((([A-ZÄÖÜa-zäöüß]+[\\-\\.\\,\\su]+)*\\s*[A-ZÄÖÜ\\sa-zäöüß]*\\d{0,3}(\\([A-ZÄÖÜ\\sa-zäöü]*\\))?[\\.\\,]*\\s*)([HIV0Ol1]*)*(\\w+\\.*\\s[1-9]+[a-z]?)*))', str(address_book_list1))\n",
    "Syntax_Personen = [item [0] for item in Personen]\n",
    "#Syntax_Personen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oil2VlDUhIlP"
   },
   "outputs": [],
   "source": [
    "'''Adding address to the person entries found by syntax'''\n",
    "temp = []\n",
    "currentStreet = []\n",
    "currentNumber = 0\n",
    "\n",
    "for i in Syntax_Personen:\n",
    "    iSplit = i.split(', ')\n",
    "    if len(iSplit) > 2:\n",
    "        street = iSplit[0]\n",
    "        houseNumber = iSplit[1]\n",
    "        if houseNumber.isdigit():\n",
    "            currentStreet = street\n",
    "            currentNumber = int(houseNumber)\n",
    "        else:\n",
    "            i = currentStreet + ', ' + str(currentNumber) + ', ' + i\n",
    "        temp.append(i)\n",
    "\n",
    "persons2 = '\\r\\n'.join(temp)\n",
    "person_txt = open('./Outputs/2_persons2.txt', 'w')\n",
    "person_txt.write(persons2)\n",
    "person_txt.close()\n",
    "\n",
    "#temp"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
